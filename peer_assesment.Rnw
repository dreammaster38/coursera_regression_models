\documentclass[10pt]{article}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{times}
\usepackage{fixltx2e}
\usepackage{float}

%\setlength{\textwidth}{6.5in} 
%\setlength{\textheight}{9in}
%\setlength{\oddsidemargin}{0in} 
%\setlength{\evensidemargin}{0in}
\usepackage{float}
\newfloat{rcode}{h!t}{rcode}
\floatname{rcode}{R-Code output}

\usepackage[left=2.0cm,right=2.0cm,top=1.5cm,bottom=-1.0cm,includeheadfoot,a4paper]{geometry}
\setlength{\topmargin}{-3.5cm}
\hypersetup{colorlinks=true}
\begin{document}

%------------------------------------------------------------
\title{Coursera Regression models peer assessment}
%------------------------------------------------------------
\author{Thomas Guenther, Germany}
%\date{}

\maketitle

\section{Executive summary}

As many may know: cars with a manual transmission performing more efficient than cars with automatic transmission. One reason is that the automatic transmission was built with comfort first in head. Furthermore it has a higher friction loss than a manual transmission and the necessary technology used to make them work is much more complicated.
The goal of this report is to answer the following particulary questions:
\begin{itemize}
  \item{Is an automatic or manual transition better for MPG?}
  \item{Quantify the MPG differene between automatic and manual transmission}
\end{itemize}
Additionally to the questions above we will do some inference to examine our car data set.
I will put this report to my github repository so anyone can see how it was build: \href{https://github.com/dreammaster38/coursera_regression_models}{here}.

\section{Automatic or manual transition? (Exploratory adventures)}
First we will take a quick look at our data set \emph{mtcars}. We have \emph{11 variables with 32 observations} in our data set. For a description of the variables please see \href{http://stat.ethz.ch/R-manual/R-devel/library/datasets/html/mtcars.html}{in the R-manual}.
Next we will do a box plot to see visually if manual transmission performs better than an automatic one or vise versa.
<<eval=FALSE,size="scriptsize">>=
p <- ggplot(mtcars.with.factored.am, aes(am, mpg, fill=am)) +
  geom_boxplot() +
  coord_cartesian(ylim=c(10,35)) +
  xlab("Type of transmission") +
  ylab("Miles per gallon") +
  ggtitle("Miles per gallon by type of transmission") +
  theme(plot.title = element_text(color="blue", size=10, vjust=1.0))  
print(p)
@

\textbf{Figure \ref{fig:boxplot}} shows us where the middle 50\% of the data can be found and the min/max values of mpg for each submission type lies. We will also see that the mpg-values of the manual transmission are right skewed. This means the values for lower mpg's are closer together.

\subsection{Examining means via t-test}
We will perform a 2-sided t-test to find out if there is a differences in the means of mpg by transmission type:
\begin{itemize}
  \item{H\textsubscript{0}: The means of mpg by transmission are equal}
  \item{H\textsubscript{1}: The means of mpg by transmission are different}
\end{itemize}
<<eval=FALSE,size="scriptsize">>=
t.test(mpg ~ am, mtcars, var.equal = FALSE)
@

Please see \textbf{R-Code output \ref{code:code1}} for the result of the code above.
As we see the p-value is much lower than 0.05 ($0.001374 < 0.05$) and the confidence interval don't contains zero. So we should reject the Null-hypothesis H\textsubscript{0} that the means are equal. We can conclude there is a difference between automatic and manual transmission as the box plot in \textbf{Figure \ref{fig:boxplot}} already turned out.

\subsection{Regression analysis}
In this section we want quantify the MPG differene between automatic and manual transmission. For this we will start with a simple linear regression and afterwards we will analyse a multivariate linear regression. A comparison of our created models including some diagnostics will round up the made effort.

\subsubsection{Simple linear regression}
The \textbf{R-Code output \ref{code:code2}} shows the simple regression model with \emph{mpg} as dependent variable and \emph{am} as independent variable. The model was generated by the following code:
<<eval=FALSE, size="scriptsize">>=
mtcars.simple.lm <- lm(mpg ~ am, data = mtcars)
@
The R-squared error is very low. That tells us that the model performance is very poor. We will now try to make it more precise with multivariate regression.

\subsubsection{Multivariate linear regression}
Now let's see if we can find a better model. To do this an approach called \textbf{\emph{"All subsets regression"}} will be applied. This algorithm inspects all possible predictor combinations and returns the \textbf{\emph{nbest}} ones. We will use \textbf{\emph{nbest=4}}. That means that we get a result containing the 4 best combinations with one predictor, the 4 best combination with two predictors, and so on, until all variables are included.
To accomplish our work we use the package \emph{leaps} and the following command to find the best 4 predictor combinations:
<<eval=FALSE, size="scriptsize">>=
best4.subsets <- regsubsets(mpg ~ ., data=mtcars, nbest=4, force.in = "am", nvmax = NULL)
plot(best4.subsets, scale="adjr2", main="Adj. R-squared plot for all subsets regression")
@
We drop in \textbf{\emph{mpg}} and all predictors, we will force that \textbf{\emph{am}} is always in the evaluation set and we want all predictor combinations tested, but only the 4 best reported back.  
Then we will do a plot of the regsubsets result (see \textbf{Figure \ref{fig:subsetplot}} ) and sort out the best predicor combinations. For simplicity we will use the \textbf{\emph{adjusted R\textsuperscript{2}}} as scaling variable for the plot. There are other methods like \textbf{Mallows Cp} to find the best combinations, but the R\textsuperscript{2} is already well known.\\
The plot shows us the predictor combinations with the best computed R\textsuperscript{2} on top. The combinations with a R\textsuperscript{2} of 0.84 in addition to our simple and full regression models are the ones we should examine a bit deeper.

<<eval=FALSE, size="scriptsize">>=
simple.fit <- lm(mpg ~ am, data = mtcars)
full.fit <- lm(mpg ~ ., data = mtcars)
subset.fit1 <- lm(mpg ~ am + disp + hp + wt + qsec, data = mtcars)
subset.fit2 <- lm(mpg ~ am + hp + wt + qsec, data = mtcars)
subset.fit3 <- lm(mpg ~ am + wt + qsec+ carb, data = mtcars)
@

\subsubsection{Diagnostics and final model selection}
Now we have to select one model from our collected 5 models above. We hope to find a good model via \emph{Akaike's Information Criterion} that suites our needs. We do this that way:
<<eval=FALSE, size="scriptsize">>=
AIC(simple.fit, full.fit, subset.fit1, subset.fit2, subset.fit3)
@
The result can be found in \textbf{R-Code output \ref{code:code3}} together with the summary of our winner model. We look for models having the lowest AIC. As we can see he models \textbf{\emph{subset.fit1 to subset.fit3}} looks promising.\\
My winner is model \textbf{subset.fit3} even if it hasn't the lowest AIC but the three subset models are close to each other. Because of the page limit i cannot plot more than one diagnostic plots to show my decision but i found the diagnostics better for that model. The dignostic plot goes to \textbf{Figure \ref{fig:diagnostic}}.
\begin{itemize}
  \item{\emph{Normality:} The Q-Q-Plot in the lower right (and also in the upper middle but without confidence envelop) in \textbf{Figure \ref{fig:diagnostic}} contains a 95\% confidence envelope and shows that most of the points are close to the line within this envelop. There are some outliers we should examine but this is left to the reader. I suggest that normality is given.}
  \item{\emph{Linearity:} The residuals vs. fitted shows no special pattern to me. All points are randomly cluttered.}
  \item{\emph{Homoscedasticity:}The plot in the upper right (Scale-location) forms a random band around the line and so have a constant variance. I suggest that there is no homoscedasdicity.}
  \item{\emph{Residual vs. Leverage:} The Residual versus Leverage shows some outliers (i.e. Chrysler Imperial). This plot is hard to interpret for me. Here we could try to remove these observations from our data set if we can find significance for our outliers and see if we get better results (This could be done with the \emph{outlierTest() function of the car package}). But we will let it for future examinations.}
\end{itemize}

If we look at the summary for model \emph{subset.fit3} we will see that thhe predictors \emph{am, wt and qseq} are significant. The predictor variables account for approx. 83.6\% of the variance in miles per gallon. It could be say: on average cars with manual transmission gets \textbf{3.5114 miles per gallon} more than cars with automatic transmission (adjusted by wt, qsec and carb).

\section{Conclusion and assumptions}
We saw that cars with manual transmission are better than with automatic transmission what we showed visually via boxplot and via a 2-sided t-test. Afterwards we quantified the difference and found out that cars with manual transmission gets \textbf{3.5114 miles per gallon} more than cars with automatic transmission. But we saw also that we did not fit a perfect model. In future sessions another regression approaches (like glm) could be applied and analyzed. We saw that we had some outliers in our data this is a further point of investigation. Some more dignostics like ANOVA, BIC and so on could also lead to better models. But all this could be analyzed another day... 

\section{Appendix}

<<echo=FALSE>>=
# initialize libraries and load data
library(ggplot2)
library(knitr)
library(leaps)
library(car)

data(mtcars)
@

<<boxplot, fig.lp="fig:", echo=FALSE, eval=TRUE, fig.height=4, fig.width=6, fig.cap="Box plot of MPG vs. transmission type", fig.pos="H">>=
mtcars.with.factored.am <- mtcars
mtcars.with.factored.am$am <- factor(mtcars$am, levels = c(0, 1), labels = c("Automatic", "Manual"))
ggplot(mtcars.with.factored.am, aes(am, mpg, fill=am)) +
  geom_boxplot() +
  coord_cartesian(ylim=c(10,35)) +
  xlab("Type of transmission") +
  ylab("Miles per gallon") +
  ggtitle("Miles per gallon by type of transmission") +
  theme(plot.title = element_text(color="blue", size=10, vjust=1.0))
@

\begin{rcode}
<<echo=FALSE, size="tiny">>=
t.test(mpg ~ am, mtcars, var.equal = FALSE)
@
\caption{Result of the 2-sided t-test for our simple regression model}\label{code:code1}
\end{rcode}

\begin{rcode}
<<size="tiny",echo=FALSE>>=
mtcars.simple.lm <- lm(mpg ~ am, data = mtcars)
summary(mtcars.simple.lm)
@
\caption{Summary of the simple linear regression model}\label{code:code2}
\end{rcode}

\begin{rcode}
<<echo=FALSE, size="tiny">>=
simple.fit <- lm(mpg ~ am, data = mtcars)
full.fit <- lm(mpg ~ ., data = mtcars)
subset.fit1 <- lm(mpg ~ am + disp + hp + wt + qsec, data = mtcars)
subset.fit2 <- lm(mpg ~ am + hp + wt + qsec, data = mtcars)
subset.fit3 <- lm(mpg ~ am + wt + qsec+ carb, data = mtcars)
print(AIC(simple.fit, full.fit, subset.fit1, subset.fit2, subset.fit3))
print(summary(subset.fit3))
@
\caption{AIC statistics and summary of our best multivariate regression model}\label{code:code3}
\end{rcode}

<<subsetplot, echo=FALSE, fig.lp="fig:", fig.height=6, fig.width=6, fig.cap="Subset regression plot", fig.pos="H">>=
best4.subsets <- regsubsets(mpg ~ ., data=mtcars, nbest=4, force.in = "am", nvmax = NULL)
plot(best4.subsets, scale="adjr2", main="Adj. R-squared plot for all subsets regression")
par(mfrow=c(1,1))
@


<<diagnostic, fig.lp="fig:", echo=FALSE, fig.height=6, fig.width=6 ,fig.cap="Diagnostic plot of our final model">>=
par(mfrow = c(2, 3), oma = c(0, 0, 2, 0))
plot(subset.fit3)

qqPlot(subset.fit3, labels=row.names(mtcars), simulate=TRUE, main="Q-Q Plot")
par(mfrow=c(1,1))
@

\end{document}